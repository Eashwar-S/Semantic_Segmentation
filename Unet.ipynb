{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Image Dimensions\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing paths to the dataset for training and testing\n",
    "TRAIN_PATH = 'dataset/stage1_train/'\n",
    "TEST_PATH = 'dataset/stage1_test/'\n",
    "\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "# print(len(train_ids))\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/670 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 670/670 [05:49<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Processing training datasets\n",
    "processing = Flase\n",
    "if processing:\n",
    "    print('Resizing training images and masks')\n",
    "\n",
    "    for n,id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "        path = TRAIN_PATH + id_\n",
    "        img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "        img = resize(img, (IMG_HEIGHT, IMG_HEIGHT), mode='constant', preserve_range=True)\n",
    "        X_train[n] = img\n",
    "\n",
    "        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype = np.bool)\n",
    "        for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "            mask_ = imread(path + '/masks/' + mask_file)\n",
    "            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n",
    "            mask = np.maximum(mask, mask_)\n",
    "        Y_train[n] = mask\n",
    "    \n",
    "    # This is done to avoid redundant processing\n",
    "    np.save('NPY files/trainingNPYfiles/TrainingData', X_train)\n",
    "    np.save('NPY files/trainingNPYfiles/Masks', Y_train)\n",
    "else:\n",
    "    print('Input image already processed. Modify processing parameter to False to process input images again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▋                                                                           | 6/65 [00:00<00:01, 45.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing testing images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 34.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Processing testing datasets\n",
    "processTrain = False\n",
    "if processTrain:\n",
    "    print('Resizing testing images')\n",
    "\n",
    "    for n,id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "        path = TEST_PATH + id_\n",
    "        img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "        sizes_test.append([img.shape[0], img.shape[1]])\n",
    "        img = resize(img, (IMG_HEIGHT, IMG_HEIGHT), mode='constant', preserve_range=True)\n",
    "        X_test[n] = img\n",
    "    \n",
    "    # This is done to avoid redundant processing\n",
    "    np.save('NPY files/testingNPYfiles/TestingData', X_test)\n",
    "else:\n",
    "    print('Testing images already processed. Modify processing parameter to False to process testing images again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
